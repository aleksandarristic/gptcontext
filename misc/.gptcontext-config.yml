# Sample .gptcontext-config.yml
# Place this file in your project root to override default configuration values

# .gptcontext-config.yml

# Maximum total tokens allowed in the generated context
MAX_TOTAL_TOKENS: 10000

# Per-file token threshold before summarization is triggered
MAX_FILE_TOKENS: 4000

# Maximum file size (in MB) to process
MAX_FILE_SIZE_MB: 2

# File extensions to include (edit as needed)
include_exts:
  - .py
  - .md
  - .json
  - .yaml
  - .yml
  - .js
  - .ts
  - .html
  - .css
  - .toml
  - .sh

# Exclusion patterns (supports globs and directories)
exclude:
  # Directory patterns
  - .git/
  - node_modules/
  - .venv/
  - dist/
  - build/
  - .mypy_cache/
  - .pytest_cache/
  - __pycache__/
  - .gptcontext-cache/
  - .idea/
  - .vscode/
  - env/
  # Glob patterns
  - "*.log"
  - "*.tmp"
  - "*.bak"
  - "*.test.*"
  - "**/__pycache__/"
  - "**/.mypy_cache/"
  - "test_*"
  # Specific files
  - ".gptcontext.txt"
  - ".gptcontext_message.txt"
  - "README.md"
  - "CHANGELOG.md"
  - "LICENSE"

# Use the built-in default excludes in addition to your list
use_default_excludes: true

# Summarizer selection ("simple" = local, "chatgpt" = OpenAI)
SUMMARIZER: "simple"

# OpenAI model (only needed if SUMMARIZER is "chatgpt")
OPENAI_MODEL: "gpt-3.5-turbo"

# Message template file (relative to project root)
message_template_file: "src/gptcontext/message_sample.txt"
